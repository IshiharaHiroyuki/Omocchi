# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †æ›¸

## ğŸ“‹ ç›®æ¬¡
1. [å‰ææ¡ä»¶ã¨ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶](#å‰ææ¡ä»¶ã¨ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶)
2. [ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †](#ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †)
3. [ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä½œæˆã¨è¨­å®š](#ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä½œæˆã¨è¨­å®š)
4. [åˆæœŸãƒ‡ãƒ¼ã‚¿ã®æŠ•å…¥](#åˆæœŸãƒ‡ãƒ¼ã‚¿ã®æŠ•å…¥)
5. [ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã®è¨­å®š](#ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã®è¨­å®š)
6. [å‹•ä½œç¢ºèª](#å‹•ä½œç¢ºèª)
7. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)
8. [ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—/ãƒªã‚¹ãƒˆã‚¢è¨­å®š](#ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒªã‚¹ãƒˆã‚¢è¨­å®š)

## ğŸ’» å‰ææ¡ä»¶ã¨ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶

### ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶
- **CPU**: 4ã‚³ã‚¢ä»¥ä¸Šæ¨å¥¨
- **ãƒ¡ãƒ¢ãƒª**: 16GBä»¥ä¸Šæ¨å¥¨ï¼ˆæœ€å°8GBï¼‰
- **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**: SSD 100GBä»¥ä¸Šï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é ˜åŸŸå«ã‚€ï¼‰
- **OS**: Linux/Windows/macOSï¼ˆDockerä½¿ç”¨æ™‚ï¼‰

### å¿…è¦ãªã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢
- Docker Engine 20.10.xä»¥ä¸Š
- Docker Compose 2.xä»¥ä¸Š
- Node.js 18.xä»¥ä¸Šï¼ˆãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ«ç”¨ï¼‰

## ğŸ› ï¸ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †

### Docker Composeè¨­å®š
ä»¥ä¸‹ã®å†…å®¹ã§`docker-compose.yml`ã‚’ä½œæˆï¼š

```yaml
version: '3.8'

services:
  postgres:
    image: postgres:14
    container_name: faq_postgres
    environment:
      POSTGRES_DB: faq_system
      POSTGRES_USER: faq_user
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    networks:
      - faq_network

  elasticsearch:
    image: elasticsearch:7.17.9
    container_name: faq_elasticsearch
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - faq_network

  redis:
    image: redis:6
    container_name: faq_redis
    command: redis-server --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - faq_network

volumes:
  postgres_data:
  elasticsearch_data:
  redis_data:

networks:
  faq_network:
    driver: bridge
```

### ç’°å¢ƒå¤‰æ•°ã®è¨­å®š
`.env`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼š

```env
POSTGRES_PASSWORD=your_secure_password
REDIS_PASSWORD=your_secure_redis_password
```

### ã‚³ãƒ³ãƒ†ãƒŠã®èµ·å‹•
```bash
# ã‚³ãƒ³ãƒ†ãƒŠã®ãƒ“ãƒ«ãƒ‰ã¨èµ·å‹•
docker-compose up -d

# ãƒ­ã‚°ã®ç¢ºèª
docker-compose logs -f
```

## ğŸ—„ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä½œæˆã¨è¨­å®š

### PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
`init-scripts/01-init.sql`ã‚’ä½œæˆï¼š

```sql
-- ã‚¹ã‚­ãƒ¼ãƒä½œæˆ
CREATE SCHEMA faq;

-- æ‹¡å¼µæ©Ÿèƒ½ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pgcrypto";

-- ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
CREATE TABLE faq.users (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
CREATE INDEX idx_users_email ON faq.users(email);
```

### Elasticsearchã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¨­å®š
```bash
# FAQã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä½œæˆ
curl -X PUT "localhost:9200/faq" -H "Content-Type: application/json" -d'
{
  "settings": {
    "number_of_shards": 1,
    "number_of_replicas": 1,
    "analysis": {
      "analyzer": {
        "custom_analyzer": {
          "type": "custom",
          "tokenizer": "kuromoji_tokenizer",
          "filter": ["kuromoji_baseform", "lowercase"]
        }
      }
    }
  }
}'
```

### Redisã®è¨­å®š
```bash
# Redisã®è¨­å®šç¢ºèª
docker-compose exec redis redis-cli -a ${REDIS_PASSWORD} CONFIG GET maxmemory-policy
```

## ğŸ“¥ åˆæœŸãƒ‡ãƒ¼ã‚¿ã®æŠ•å…¥

### ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä½œæˆ
`migrations/seed.js`ã‚’ä½œæˆï¼š

```javascript
const { Pool } = require('pg');
const fs = require('fs').promises;

const pool = new Pool({
  user: 'faq_user',
  password: process.env.POSTGRES_PASSWORD,
  host: 'localhost',
  database: 'faq_system',
  port: 5432,
});

async function seedDatabase() {
  try {
    // ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    const data = await fs.readFile('./seed-data.json', 'utf8');
    const seedData = JSON.parse(data);

    // ãƒ‡ãƒ¼ã‚¿æŠ•å…¥
    for (const item of seedData) {
      await pool.query(
        'INSERT INTO faq.users (email, password_hash) VALUES ($1, $2)',
        [item.email, item.password_hash]
      );
    }

    console.log('Seed data inserted successfully');
  } catch (err) {
    console.error('Error seeding database:', err);
    throw err;
  } finally {
    await pool.end();
  }
}

seedDatabase();
```

### åˆæœŸãƒ‡ãƒ¼ã‚¿ã®å®Ÿè¡Œ
```bash
# ç’°å¢ƒå¤‰æ•°ã®è¨­å®š
export POSTGRES_PASSWORD=your_secure_password

# ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ
node migrations/seed.js
```

## ğŸ”’ ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã®è¨­å®š

### PostgreSQLãƒ¦ãƒ¼ã‚¶ãƒ¼æ¨©é™
```sql
-- èª­ã¿å–ã‚Šå°‚ç”¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä½œæˆ
CREATE ROLE readonly_user WITH LOGIN PASSWORD 'readonly_password';
GRANT USAGE ON SCHEMA faq TO readonly_user;
GRANT SELECT ON ALL TABLES IN SCHEMA faq TO readonly_user;

-- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä½œæˆ
CREATE ROLE app_user WITH LOGIN PASSWORD 'app_password';
GRANT USAGE, CREATE ON SCHEMA faq TO app_user;
GRANT ALL PRIVILEGES ON ALL TABLES IN SCHEMA faq TO app_user;
```

### Elasticsearchãƒ­ãƒ¼ãƒ«è¨­å®š
```bash
# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šã®è¿½åŠ 
curl -X PUT "localhost:9200/_security/role/faq_read" -H "Content-Type: application/json" -d'
{
  "indices": [
    {
      "names": ["faq"],
      "privileges": ["read"]
    }
  ]
}'
```

## âœ… å‹•ä½œç¢ºèª

### PostgreSQLæ¥ç¶šãƒ†ã‚¹ãƒˆ
```bash
# psqlã§ã®æ¥ç¶šç¢ºèª
docker-compose exec postgres psql -U faq_user -d faq_system

# ãƒ†ã‚¹ãƒˆã‚¯ã‚¨ãƒªã®å®Ÿè¡Œ
SELECT COUNT(*) FROM faq.users;
```

### Elasticsearchå‹•ä½œç¢ºèª
```bash
# ã‚¯ãƒ©ã‚¹ã‚¿ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
curl -X GET "localhost:9200/_cluster/health?pretty"

# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç¢ºèª
curl -X GET "localhost:9200/_cat/indices?v"
```

### Rediså‹•ä½œç¢ºèª
```bash
# Redisã¸ã®æ¥ç¶šç¢ºèª
docker-compose exec redis redis-cli -a ${REDIS_PASSWORD} ping
```

## â— ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•

1. **PostgreSQLã‚³ãƒ³ãƒ†ãƒŠãŒèµ·å‹•ã—ãªã„**
```bash
# ãƒ­ã‚°ã®ç¢ºèª
docker-compose logs postgres

# ãƒ‡ãƒ¼ã‚¿ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®ã‚¯ãƒªã‚¢ï¼ˆæ³¨æ„ï¼šãƒ‡ãƒ¼ã‚¿ãŒå‰Šé™¤ã•ã‚Œã¾ã™ï¼‰
docker-compose down -v
docker-compose up -d
```

2. **Elasticsearchã®ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼**
```bash
# ã‚·ã‚¹ãƒ†ãƒ ã®è¨­å®šç¢ºèª
sysctl -w vm.max_map_count=262144

# Elasticsearchã®å†èµ·å‹•
docker-compose restart elasticsearch
```

3. **Redisã®æ¥ç¶šã‚¨ãƒ©ãƒ¼**
```bash
# Redisã‚³ãƒ³ãƒ†ãƒŠã®çŠ¶æ…‹ç¢ºèª
docker-compose ps redis

# è¨­å®šã®ç¢ºèª
docker-compose exec redis redis-cli -a ${REDIS_PASSWORD} INFO
```

## ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—/ãƒªã‚¹ãƒˆã‚¢è¨­å®š

### PostgreSQLãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨­å®š

1. **å®šæœŸãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**
`scripts/backup-postgres.sh`ã‚’ä½œæˆï¼š

```bash
#!/bin/bash
BACKUP_DIR="/backup/postgres"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="faq_system_${TIMESTAMP}.dump"

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å®Ÿè¡Œ
docker-compose exec -T postgres pg_dump -U faq_user faq_system > "${BACKUP_DIR}/${BACKUP_FILE}"

# 30æ—¥ä»¥ä¸Šå‰ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤
find ${BACKUP_DIR} -name "faq_system_*.dump" -mtime +30 -delete
```

2. **ãƒªã‚¹ãƒˆã‚¢ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**
`scripts/restore-postgres.sh`ã‚’ä½œæˆï¼š

```bash
#!/bin/bash
BACKUP_FILE=$1

if [ -z "$BACKUP_FILE" ]; then
  echo "Usage: $0 <backup-file>"
  exit 1
fi

# ãƒªã‚¹ãƒˆã‚¢ã®å®Ÿè¡Œ
docker-compose exec -T postgres psql -U faq_user faq_system < "${BACKUP_FILE}"
```

### Elasticsearchã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆè¨­å®š

1. **ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆãƒªãƒã‚¸ãƒˆãƒªã®ç™»éŒ²**
```bash
# ãƒªãƒã‚¸ãƒˆãƒªã®ç™»éŒ²
curl -X PUT "localhost:9200/_snapshot/faq_backup" -H "Content-Type: application/json" -d'
{
  "type": "fs",
  "settings": {
    "location": "/usr/share/elasticsearch/backup"
  }
}'
```

2. **ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã®ä½œæˆ**
```bash
# ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã®å®Ÿè¡Œ
curl -X PUT "localhost:9200/_snapshot/faq_backup/snapshot_1?wait_for_completion=true"
```

### Redisãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨­å®š

1. **Redisè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°**
```conf
dir /data
dbfilename dump.rdb
save 900 1
save 300 10
save 60 10000
```

2. **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**
`scripts/backup-redis.sh`ã‚’ä½œæˆï¼š

```bash
#!/bin/bash
BACKUP_DIR="/backup/redis"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

# BAKEã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè¡Œ
docker-compose exec -T redis redis-cli -a ${REDIS_PASSWORD} SAVE

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ”ãƒ¼
docker cp faq_redis:/data/dump.rdb "${BACKUP_DIR}/dump_${TIMESTAMP}.rdb"

# å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å‰Šé™¤
find ${BACKUP_DIR} -name "dump_*.rdb" -mtime +30 -delete
```

### Cronã‚¸ãƒ§ãƒ–ã®è¨­å®š
```bash
# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®è‡ªå‹•åŒ–
0 1 * * * /path/to/scripts/backup-postgres.sh
0 2 * * * /path/to/scripts/backup-redis.sh
0 3 * * * curl -X PUT "localhost:9200/_snapshot/faq_backup/snapshot_$(date +\%Y\%m\%d)"
```

### æ³¨æ„äº‹é …
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯å¿…ãšåˆ¥ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ä¿å­˜ã™ã‚‹ã“ã¨
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ãƒªã‚¹ãƒˆã‚¢ãƒ†ã‚¹ãƒˆã‚’å®šæœŸçš„ã«å®Ÿæ–½ã™ã‚‹ã“ã¨
- ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ­ã‚°ã‚’å®šæœŸçš„ã«ç¢ºèªã™ã‚‹ã“ã¨
- ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãªãƒ‡ãƒ¼ã‚¿ã¯è¤‡æ•°ã®å ´æ‰€ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä¿ç®¡ã™ã‚‹ã“ã¨